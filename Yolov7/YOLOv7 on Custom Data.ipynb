{"cells":[{"cell_type":"markdown","metadata":{"id":"GD9gUQpaBxNa"},"source":["# How to Train YOLOv7 on a Custom Dataset\n","\n","This tutorial is based on the [YOLOv7 repository](https://github.com/WongKinYiu/yolov7) by WongKinYiu. This notebook shows training on **your own custom objects**. Many thanks to WongKinYiu and AlexeyAB for putting this repository together.\n","\n","\n","### **Accompanying Blog Post**\n","\n","We recommend that you follow along in this notebook while reading the blog post on [how to train YOLOv7](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/), concurrently.\n","\n","### **Steps Covered in this Tutorial**\n","\n","To train our detector we take the following steps:\n","\n","* Install YOLOv7 dependencies\n","* Load custom dataset from Roboflow in YOLOv7 format\n","* Run YOLOv7 training\n","* Evaluate YOLOv7 performance\n","* Run YOLOv7 inference on test images\n","* OPTIONAL: Deployment\n","* OPTIONAL: Active Learning\n","\n","\n","### Preparing a Custom Dataset\n","\n","In this tutorial, we will utilize an open source computer vision dataset from one of the 90,000+ available on [Roboflow Universe](https://universe.roboflow.com).\n","\n","If you already have your own images (and, optionally, annotations), you can convert your dataset using [Roboflow](https://roboflow.com), a set of tools developers use to build better computer vision models quickly and accurately. 100k+ developers use roboflow for (automatic) annotation, converting dataset formats (like to YOLOv7), training, deploying, and improving their datasets/models.\n","\n","Follow [the getting started guide here](https://docs.roboflow.com/quick-start) to create and prepare your own custom dataset."]},{"cell_type":"markdown","source":["# Mount Google Drive"],"metadata":{"id":"3i_Hm89Sq1LX"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"W5ChXi8qQ8nx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695306273280,"user_tz":-300,"elapsed":20616,"user":{"displayName":"Fatima Naweed","userId":"10568646159859638492"}},"outputId":"fd269722-639e-4fde-bca5-d3d1d248dfb3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"]},{"cell_type":"markdown","metadata":{"id":"7mGmQbAO5pQb"},"source":["#Install Dependencies\n","\n","_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":652,"status":"ok","timestamp":1695306273924,"user":{"displayName":"Fatima Naweed","userId":"10568646159859638492"},"user_tz":-300},"id":"HXzonuEtXBQz","outputId":"b8fb2a15-5702-48bb-cca7-3569f2c63a22"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/SPROJ/GitHub/yolo\n"]}],"source":["%cd /content/drive/MyDrive/SPROJ/GitHub/yolo"]},{"cell_type":"markdown","source":["Clone GitHub Repo if needed. We already have our repo uploaded so there is no need."],"metadata":{"id":"0o-xvqguq-9A"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nD-uPyQ_2jiN"},"outputs":[],"source":["# Download YOLOv7 repository and install requirements\n","# !git clone https://github.com/WongKinYiu/yolov7\n","# %cd yolov7\n","# !pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"mtJ24mPlyF-S"},"source":["# Download Correctly Formatted Custom Data\n","\n","Next, we'll download our dataset in the right format. Use the `YOLOv7 PyTorch` export. Note that this model requires YOLO TXT annotations, a custom YAML file, and organized directories. The roboflow export writes this for us and saves it in the correct spot.\n"]},{"cell_type":"markdown","source":["We are uploading the txt file since we made some changes to the data.yaml file to fix dataset path error"],"metadata":{"id":"8hMci9gCrMJF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ovKgrVN8ygdW"},"outputs":[],"source":["# !pip install roboflow\n","\n","# from roboflow import Roboflow\n","# rf = Roboflow(api_key=\"0sERzwSbCfOmHIHzY2Hz\")\n","# project = rf.workspace(\"sprojfinaldataset\").project(\"sharjeel-and-daim-final-dataset-oeskc\")\n","# dataset = project.version(2).download(\"yolov7\")"]},{"cell_type":"markdown","metadata":{"id":"bHfT9gEiBsBd"},"source":["# Begin Custom Training\n","\n","We're ready to start custom training.\n","\n","NOTE: We will only modify one of the YOLOv7 training defaults in our example: `epochs`. We will adjust from 300 to 100 epochs in our example for speed. If you'd like to change other settings, see details in [our accompanying blog post](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bUbmy674bhpD"},"outputs":[],"source":["# %cd /content/drive/MyDrive/SPROJ/newYolo/yolov7\n","# # download COCO starting checkpoint - REQUIRED IF TRAINING FROM SCRATCH\n","# !wget \"https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1iqOPKjr22mL"},"outputs":[],"source":["# %cd /content/drive/MyDrive/SPROJ/yolov7/yolov7-main\n","# !python train.py --batch 16 --cfg cfg/training/yolov7.yaml --epochs 50 --data Final-DS-2/data.yaml --weights 'yolov7.pt' --device 0"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2250,"status":"ok","timestamp":1695306598032,"user":{"displayName":"Fatima Naweed","userId":"10568646159859638492"},"user_tz":-300},"id":"l_prZ12e8erO","outputId":"af0cb8e8-afa9-4406-8969-6567389d188a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/SPROJ/GitHub\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/SPROJ/GitHub/yolo/train.py\", line 21, in <module>\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py\", line 2, in <module>\n","    from distutils.version import LooseVersion\n","  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 1002, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 945, in _find_spec\n","  File \"/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py\", line 97, in find_spec\n","    return method()\n","  File \"/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py\", line 108, in spec_for_distutils\n","    mod = importlib.import_module('setuptools._distutils')\n","  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n","    return _bootstrap._gcd_import(name[level:], package, level)\n","  File \"/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py\", line 17, in <module>\n","    from setuptools.dist import Distribution\n","  File \"/usr/local/lib/python3.10/dist-packages/setuptools/dist.py\", line 37, in <module>\n","    from setuptools.config import setupcfg, pyprojecttoml\n","  File \"/usr/local/lib/python3.10/dist-packages/setuptools/config/__init__.py\", line 8, in <module>\n","    from . import setupcfg\n","  File \"/usr/local/lib/python3.10/dist-packages/setuptools/config/setupcfg.py\", line 33, in <module>\n","    from ..extern.packaging.markers import default_environment as marker_env\n","  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_vendor/packaging/markers.py\", line 11, in <module>\n","    from ._parser import MarkerAtom, MarkerList, Op, Value, Variable, parse_marker\n","  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_vendor/packaging/_parser.py\", line 10, in <module>\n","    from ._tokenizer import DEFAULT_RULES, Tokenizer\n","  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_vendor/packaging/_tokenizer.py\", line 74, in <module>\n","    \"SPECIFIER\": re.compile(\n","  File \"/usr/lib/python3.10/re.py\", line 251, in compile\n","    return _compile(pattern, flags)\n","  File \"/usr/lib/python3.10/re.py\", line 303, in _compile\n","    p = sre_compile.compile(pattern, flags)\n","  File \"/usr/lib/python3.10/sre_compile.py\", line 788, in compile\n","    p = sre_parse.parse(p, flags)\n","  File \"/usr/lib/python3.10/sre_parse.py\", line 955, in parse\n","    p = _parse_sub(source, state, flags & SRE_FLAG_VERBOSE, 0)\n","  File \"/usr/lib/python3.10/sre_parse.py\", line 444, in _parse_sub\n","    itemsappend(_parse(source, state, verbose, nested + 1,\n","  File \"/usr/lib/python3.10/sre_parse.py\", line 841, in _parse\n","    p = _parse_sub(source, state, sub_verbose, nested + 1)\n","  File \"/usr/lib/python3.10/sre_parse.py\", line 444, in _parse_sub\n","    itemsappend(_parse(source, state, verbose, nested + 1,\n","  File \"/usr/lib/python3.10/sre_parse.py\", line 841, in _parse\n","    p = _parse_sub(source, state, sub_verbose, nested + 1)\n","  File \"/usr/lib/python3.10/sre_parse.py\", line 444, in _parse_sub\n","    itemsappend(_parse(source, state, verbose, nested + 1,\n","  File \"/usr/lib/python3.10/sre_parse.py\", line 841, in _parse\n","    p = _parse_sub(source, state, sub_verbose, nested + 1)\n","  File \"/usr/lib/python3.10/sre_parse.py\", line 444, in _parse_sub\n","    itemsappend(_parse(source, state, verbose, nested + 1,\n","  File \"/usr/lib/python3.10/sre_parse.py\", line 841, in _parse\n","    p = _parse_sub(source, state, sub_verbose, nested + 1)\n","  File \"/usr/lib/python3.10/sre_parse.py\", line 444, in _parse_sub\n","    itemsappend(_parse(source, state, verbose, nested + 1,\n","  File \"/usr/lib/python3.10/sre_parse.py\", line 678, in _parse\n","    if sourcematch(\"?\"):\n","  File \"/usr/lib/python3.10/sre_parse.py\", line 250, in match\n","    def match(self, char):\n","KeyboardInterrupt\n","^C\n"]}],"source":["%cd /content/drive/MyDrive/SPROJ/GitHub\n","!python yolo/train.py\\\n","--batch 16 \\\n","--cfg yolo/cfg/training/yolov7.yaml\\\n","--epochs 100\\\n","--data Dataset/data.yaml\\\n","--weights yolo/yolov7.pt \\\n","--device 0"]},{"cell_type":"markdown","metadata":{"id":"0W0MpUaTCJro"},"source":["# Evaluation\n","\n","We can evaluate the performance of our custom training using the provided evalution script.\n","\n","Note we can adjust the below custom arguments. For details, see [the arguments accepted by detect.py](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4cfnLtTCIce"},"outputs":[],"source":["# Run evaluation\n","%cd /content/drive/MyDrive/SPROJ/newYolo/yolov7/\n","!python detect.py --weights runs/train/normal/weights/best.pt --conf 0.1 --source Finalest-DS-2/new_sample_real --iou-thres 0.00"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1X9A8odmK4k6l26NDviiT6dd6TgR-piOa","timestamp":1661087952498},{"file_id":"1YnbqOinBZV-c9I7fk_UL6acgnnmkXDMM","timestamp":1657587444672},{"file_id":"1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ","timestamp":1656523193068},{"file_id":"https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb","timestamp":1591755516488}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}